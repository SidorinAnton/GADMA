Data reading
[93mUserWarning: Spectrum file /home/katenos/Workspace/popgen/temp/GADMA/examples/changing_theta/YRI_CEU.fs is in an old format - without population labels, so they will be taken from the corresponding parameter: YRI, CEU.[0m (/home/katenos/.local/lib/python3.6/site-packages/gadma-2.0.0rc11.dev21-py3.6.egg/gadma/engines/dadi_moments_common.py:284)
Number of populations: 2
Projections: [20, 20]
Population labels: ['YRI', 'CEU']
Outgroup: True
[92m--Successful data reading--[0m

[92m--Successful arguments parsing--[0m

Parameters of launch are saved in output directory: /home/katenos/Workspace/popgen/temp/GADMA/my_example_run_2/params_file
All output is saved in output directory: /home/katenos/Workspace/popgen/temp/GADMA/my_example_run_2/GADMA.log

[94m--Start pipeline--[0m
Run launch number 3
Run launch number 1
Run launch number 2

[000:01:00]
All best by log-likelihood models
Number	log-likelihood	Model
Run 3	-1371.82	 [Nanc = 7310] [ [ 16679.659(t1), [7310.323(nu11)], [Sud(dyn11)] ],	[ 1 pop split   47.00% (s1) [3436.143(s1*nu11), 3874.18((1-s1)*nu11)] ],	[ 8411.478(t2), [16355.95(nu21), 2856.27(nu22)], [[0, 7.26e-05(m2_12)], [1.92e-04(m2_21), 0]], [Exp(dyn21), Lin(dyn22)] ] ]	(theta =  2776.17)
Run 1	-2085.85	 [Nanc = 1819] [ [ 4800.718(t1), [18843.512(nu11)], [Sud(dyn11)] ],	[ 1 pop split   41.87% (s1) [7889.086(s1*nu11), 10954.426((1-s1)*nu11)] ],	[ 17721.282(t2), [18055.73(nu21), 790.355(nu22)], [[0, 5.69e-05(m2_12)], [4.95e-04(m2_21), 0]], [Exp(dyn21), Sud(dyn22)] ] ]	c	(theta =  691.09)
Run 2	-2318.60	 [Nanc = 5325] [ [ 11872.429(t1), [5325.096(nu11)], [Sud(dyn11)] ],	[ 1 pop split   46.07% (s1) [2453.331(s1*nu11), 2871.766((1-s1)*nu11)] ],	[ 4120.521(t2), [100843.038(nu21), 13239.143(nu22)], [[0, 5.65e-05(m2_12)], [2.35e-05(m2_21), 0]], [Exp(dyn21), Exp(dyn22)] ] ]	c	(theta =  2022.26)
Finish genetic algorithm number 1

You can find the picture and the Python code of the best model in the output directory.

Finish genetic algorithm number 2

[000:02:00]
All best by log-likelihood models
Number	log-likelihood	Model
Run 3	-1158.60	 [Nanc = 7338] [ [ 16713.939(t1), [7112.687(nu11)], [Sud(dyn11)] ],	[ 1 pop split   70.32% (s1) [5001.556(s1*nu11), 2111.13((1-s1)*nu11)] ],	[ 9437.271(t2), [15263.689(nu21), 3194.151(nu22)], [[0, 1.29e-04(m2_12)], [1.24e-04(m2_21), 0]], [Exp(dyn21), Lin(dyn22)] ] ]	(theta =  2786.78)
Run 2	-1565.26	 [Nanc = 5680] [ [ 12664.975(t1), [6921.832(nu11)], [Sud(dyn11)] ],	[ 1 pop split   72.13% (s1) [4992.791(s1*nu11), 1929.041((1-s1)*nu11)] ],	[ 3189.766(t2), [98619.538(nu21), 8914.86(nu22)], [[0, 5.38e-05(m2_12)], [2.05e-05(m2_21), 0]], [Exp(dyn21), Exp(dyn22)] ] ]	f	(theta =  2157.25)
Run 1	-2085.85	 [Nanc = 1819] [ [ 4800.718(t1), [18843.512(nu11)], [Sud(dyn11)] ],	[ 1 pop split   41.87% (s1) [7889.086(s1*nu11), 10954.426((1-s1)*nu11)] ],	[ 17721.282(t2), [18055.73(nu21), 790.355(nu22)], [[0, 5.69e-05(m2_12)], [4.95e-04(m2_21), 0]], [Exp(dyn21), Sud(dyn22)] ] ]	c	(theta =  691.09)

You can find the picture and the Python code of the best model in the output directory.


[000:03:00]
All best by log-likelihood models
Number	log-likelihood	Model
Run 3	-1102.49	 [Nanc = 6284] [ [ 12477.003(t1), [10639.218(nu11)], [Sud(dyn11)] ],	[ 1 pop split   92.65% (s1) [9857.418(s1*nu11), 781.8((1-s1)*nu11)] ],	[ 2526.257(t2), [17225.038(nu21), 5175.936(nu22)], [[0, 1.13e-04(m2_12)], [5.72e-05(m2_21), 0]], [Exp(dyn21), Lin(dyn22)] ] ]	(theta =  2386.44)
Run 2	-1565.26	 [Nanc = 5680] [ [ 12664.975(t1), [6921.832(nu11)], [Sud(dyn11)] ],	[ 1 pop split   72.13% (s1) [4992.791(s1*nu11), 1929.041((1-s1)*nu11)] ],	[ 3189.766(t2), [98619.538(nu21), 8914.86(nu22)], [[0, 5.38e-05(m2_12)], [2.05e-05(m2_21), 0]], [Exp(dyn21), Exp(dyn22)] ] ]	f	(theta =  2157.25)
Run 1	-2085.85	 [Nanc = 1819] [ [ 4800.718(t1), [18843.512(nu11)], [Sud(dyn11)] ],	[ 1 pop split   41.87% (s1) [7889.086(s1*nu11), 10954.426((1-s1)*nu11)] ],	[ 17721.282(t2), [18055.73(nu21), 790.355(nu22)], [[0, 5.69e-05(m2_12)], [4.95e-04(m2_21), 0]], [Exp(dyn21), Sud(dyn22)] ] ]	c	(theta =  691.09)

You can find the picture and the Python code of the best model in the output directory.


[000:04:00]
All best by log-likelihood models
Number	log-likelihood	Model
Run 3	-1075.77	 [Nanc = 7150] [ [ 6790.07(t1), [11915.577(nu11)], [Sud(dyn11)] ],	[ 1 pop split   98.66% (s1) [11756.253(s1*nu11), 159.324((1-s1)*nu11)] ],	[ 1607.082(t2), [16895.378(nu21), 7316.577(nu22)], [[0, 5.15e-05(m2_12)], [4.61e-05(m2_21), 0]], [Exp(dyn21), Lin(dyn22)] ] ]	(theta =  2715.64)
Run 2	-1565.26	 [Nanc = 5680] [ [ 12664.975(t1), [6921.832(nu11)], [Sud(dyn11)] ],	[ 1 pop split   72.13% (s1) [4992.791(s1*nu11), 1929.041((1-s1)*nu11)] ],	[ 3189.766(t2), [98619.538(nu21), 8914.86(nu22)], [[0, 5.38e-05(m2_12)], [2.05e-05(m2_21), 0]], [Exp(dyn21), Exp(dyn22)] ] ]	f	(theta =  2157.25)
Run 1	-2085.85	 [Nanc = 1819] [ [ 4800.718(t1), [18843.512(nu11)], [Sud(dyn11)] ],	[ 1 pop split   41.87% (s1) [7889.086(s1*nu11), 10954.426((1-s1)*nu11)] ],	[ 17721.282(t2), [18055.73(nu21), 790.355(nu22)], [[0, 5.69e-05(m2_12)], [4.95e-04(m2_21), 0]], [Exp(dyn21), Sud(dyn22)] ] ]	c	(theta =  691.09)

You can find the picture and the Python code of the best model in the output directory.


[000:05:00]
All best by log-likelihood models
Number	log-likelihood	Model
Run 3	-1065.53	 [Nanc = 7210] [ [ 5448.399(t1), [13746.912(nu11)], [Sud(dyn11)] ],	[ 1 pop split   99.66% (s1) [13700.577(s1*nu11), 46.335((1-s1)*nu11)] ],	[ 1454.529(t2), [12861.753(nu21), 8356.604(nu22)], [[0, 6.20e-05(m2_12)], [6.10e-05(m2_21), 0]], [Exp(dyn21), Lin(dyn22)] ] ]	(theta =  2738.16)
Run 2	-1565.26	 [Nanc = 5680] [ [ 12664.975(t1), [6921.832(nu11)], [Sud(dyn11)] ],	[ 1 pop split   72.13% (s1) [4992.791(s1*nu11), 1929.041((1-s1)*nu11)] ],	[ 3189.766(t2), [98619.538(nu21), 8914.86(nu22)], [[0, 5.38e-05(m2_12)], [2.05e-05(m2_21), 0]], [Exp(dyn21), Exp(dyn22)] ] ]	f	(theta =  2157.25)
Run 1	-2085.85	 [Nanc = 1819] [ [ 4800.718(t1), [18843.512(nu11)], [Sud(dyn11)] ],	[ 1 pop split   41.87% (s1) [7889.086(s1*nu11), 10954.426((1-s1)*nu11)] ],	[ 17721.282(t2), [18055.73(nu21), 790.355(nu22)], [[0, 5.69e-05(m2_12)], [4.95e-04(m2_21), 0]], [Exp(dyn21), Sud(dyn22)] ] ]	c	(theta =  691.09)

You can find the picture and the Python code of the best model in the output directory.


[000:06:00]
All best by log-likelihood models
Number	log-likelihood	Model
Run 3	-1065.27	 [Nanc = 7230] [ [ 5218.259(t1), [14132.372(nu11)], [Sud(dyn11)] ],	[ 1 pop split   99.79% (s1) [14102.176(s1*nu11), 30.197((1-s1)*nu11)] ],	[ 1387.067(t2), [12459.778(nu21), 8843.315(nu22)], [[0, 5.95e-05(m2_12)], [5.93e-05(m2_21), 0]], [Exp(dyn21), Lin(dyn22)] ] ]	(theta =  2745.96)
Run 2	-1565.26	 [Nanc = 5680] [ [ 12664.975(t1), [6921.832(nu11)], [Sud(dyn11)] ],	[ 1 pop split   72.13% (s1) [4992.791(s1*nu11), 1929.041((1-s1)*nu11)] ],	[ 3189.766(t2), [98619.538(nu21), 8914.86(nu22)], [[0, 5.38e-05(m2_12)], [2.05e-05(m2_21), 0]], [Exp(dyn21), Exp(dyn22)] ] ]	f	(theta =  2157.25)
Run 1	-2085.85	 [Nanc = 1819] [ [ 4800.718(t1), [18843.512(nu11)], [Sud(dyn11)] ],	[ 1 pop split   41.87% (s1) [7889.086(s1*nu11), 10954.426((1-s1)*nu11)] ],	[ 17721.282(t2), [18055.73(nu21), 790.355(nu22)], [[0, 5.69e-05(m2_12)], [4.95e-04(m2_21), 0]], [Exp(dyn21), Sud(dyn22)] ] ]	c	(theta =  691.09)

You can find the picture and the Python code of the best model in the output directory.


[000:07:00]
All best by log-likelihood models
Number	log-likelihood	Model
Run 3	-1065.27	 [Nanc = 7230] [ [ 5218.38(t1), [14132.072(nu11)], [Sud(dyn11)] ],	[ 1 pop split   99.79% (s1) [14101.874(s1*nu11), 30.198((1-s1)*nu11)] ],	[ 1387.08(t2), [12460.354(nu21), 8843.363(nu22)], [[0, 5.95e-05(m2_12)], [5.93e-05(m2_21), 0]], [Exp(dyn21), Lin(dyn22)] ] ]	(theta =  2745.96)
Run 2	-1565.26	 [Nanc = 5680] [ [ 12664.975(t1), [6921.832(nu11)], [Sud(dyn11)] ],	[ 1 pop split   72.13% (s1) [4992.791(s1*nu11), 1929.041((1-s1)*nu11)] ],	[ 3189.766(t2), [98619.538(nu21), 8914.86(nu22)], [[0, 5.38e-05(m2_12)], [2.05e-05(m2_21), 0]], [Exp(dyn21), Exp(dyn22)] ] ]	f	(theta =  2157.25)
Run 1	-2085.85	 [Nanc = 1819] [ [ 4800.718(t1), [18843.512(nu11)], [Sud(dyn11)] ],	[ 1 pop split   41.87% (s1) [7889.086(s1*nu11), 10954.426((1-s1)*nu11)] ],	[ 17721.282(t2), [18055.73(nu21), 790.355(nu22)], [[0, 5.69e-05(m2_12)], [4.95e-04(m2_21), 0]], [Exp(dyn21), Sud(dyn22)] ] ]	c	(theta =  691.09)

You can find the picture and the Python code of the best model in the output directory.

Finish genetic algorithm number 3

[000:07:55]
All best by log-likelihood models
Number	log-likelihood	Model
Run 3	-1065.27	 [Nanc = 7230] [ [ 5218.38(t1), [14132.072(nu11)], [Sud(dyn11)] ],	[ 1 pop split   99.79% (s1) [14101.874(s1*nu11), 30.198((1-s1)*nu11)] ],	[ 1387.08(t2), [12460.354(nu21), 8843.363(nu22)], [[0, 5.95e-05(m2_12)], [5.93e-05(m2_21), 0]], [Exp(dyn21), Lin(dyn22)] ] ]	f	(theta =  2745.96)
Run 2	-1565.26	 [Nanc = 5680] [ [ 12664.975(t1), [6921.832(nu11)], [Sud(dyn11)] ],	[ 1 pop split   72.13% (s1) [4992.791(s1*nu11), 1929.041((1-s1)*nu11)] ],	[ 3189.766(t2), [98619.538(nu21), 8914.86(nu22)], [[0, 5.38e-05(m2_12)], [2.05e-05(m2_21), 0]], [Exp(dyn21), Exp(dyn22)] ] ]	f	(theta =  2157.25)
Run 1	-2085.85	 [Nanc = 1819] [ [ 4800.718(t1), [18843.512(nu11)], [Sud(dyn11)] ],	[ 1 pop split   41.87% (s1) [7889.086(s1*nu11), 10954.426((1-s1)*nu11)] ],	[ 17721.282(t2), [18055.73(nu21), 790.355(nu22)], [[0, 5.69e-05(m2_12)], [4.95e-04(m2_21), 0]], [Exp(dyn21), Sud(dyn22)] ] ]	c	(theta =  691.09)

You can find the picture and the Python code of the best model in the output directory.


--Finish pipeline--

Thank you for using GADMA!

In case of any questions or problems, please contact: ekaterina.e.noskova@gmail.com

